{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST download from torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train using: mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('mps')\n",
    "print(f'Train using: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
    "                          train=True,\n",
    "                          transform=transforms.ToTensor(),\n",
    "                          download=True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
    "                         train=False,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWhy drop_last = True? \\n-> drop_last를 하는 이유를 이해하기 위해서 1,000개의 데이터가 있다고 했을 때, 배치 크기가 128이라고 해봅시다. \\n1,000을 128로 나누면 총 7개가 나오고 나머지로 104개가 남습니다. \\n이때 104개를 마지막 배치로 한다고 하였을 때 128개를 충족하지 못하였으므로 104개를 그냥 버릴 수도 있습니다. \\n이때 마지막 배치를 버리려면 drop_last=True를 해주면 됩니다. \\n이는 다른 미니 배치보다 개수가 적은 마지막 배치를 경사 하강법에 사용하여 마지막 배치가 상대적으로 과대 평가되는 현상을 막아줍니다.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = DataLoader(dataset=mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "\"\"\"\n",
    "Why drop_last = True? \n",
    "-> drop_last를 하는 이유를 이해하기 위해서 1,000개의 데이터가 있다고 했을 때, 배치 크기가 128이라고 해봅시다. \n",
    "1,000을 128로 나누면 총 7개가 나오고 나머지로 104개가 남습니다. \n",
    "이때 104개를 마지막 배치로 한다고 하였을 때 128개를 충족하지 못하였으므로 104개를 그냥 버릴 수도 있습니다. \n",
    "이때 마지막 배치를 버리려면 drop_last=True를 해주면 됩니다. \n",
    "이는 다른 미니 배치보다 개수가 적은 마지막 배치를 경사 하강법에 사용하여 마지막 배치가 상대적으로 과대 평가되는 현상을 막아줍니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = nn.Linear(784, 10, bias=True).to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(linear.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs:    0/ 100, loss: 0.635305 \n",
      "Epochs:    1/ 100, loss: 0.228254 \n",
      "Epochs:    2/ 100, loss: 0.424329 \n",
      "Epochs:    3/ 100, loss: 0.176563 \n",
      "Epochs:    4/ 100, loss: 0.364699 \n",
      "Epochs:    5/ 100, loss: 0.350599 \n",
      "Epochs:    6/ 100, loss: 0.324628 \n",
      "Epochs:    7/ 100, loss: 0.206336 \n",
      "Epochs:    8/ 100, loss: 0.296542 \n",
      "Epochs:    9/ 100, loss: 0.223997 \n",
      "Epochs:   10/ 100, loss: 0.234409 \n",
      "Epochs:   11/ 100, loss: 0.419023 \n",
      "Epochs:   12/ 100, loss: 0.252132 \n",
      "Epochs:   13/ 100, loss: 0.167446 \n",
      "Epochs:   14/ 100, loss: 0.199012 \n",
      "Epochs:   15/ 100, loss: 0.231792 \n",
      "Epochs:   16/ 100, loss: 0.219995 \n",
      "Epochs:   17/ 100, loss: 0.266404 \n",
      "Epochs:   18/ 100, loss: 0.291756 \n",
      "Epochs:   19/ 100, loss: 0.158132 \n",
      "Epochs:   20/ 100, loss: 0.275450 \n",
      "Epochs:   21/ 100, loss: 0.211971 \n",
      "Epochs:   22/ 100, loss: 0.249947 \n",
      "Epochs:   23/ 100, loss: 0.231550 \n",
      "Epochs:   24/ 100, loss: 0.318432 \n",
      "Epochs:   25/ 100, loss: 0.189249 \n",
      "Epochs:   26/ 100, loss: 0.347133 \n",
      "Epochs:   27/ 100, loss: 0.275720 \n",
      "Epochs:   28/ 100, loss: 0.227257 \n",
      "Epochs:   29/ 100, loss: 0.287904 \n",
      "Epochs:   30/ 100, loss: 0.169894 \n",
      "Epochs:   31/ 100, loss: 0.222484 \n",
      "Epochs:   32/ 100, loss: 0.176587 \n",
      "Epochs:   33/ 100, loss: 0.279437 \n",
      "Epochs:   34/ 100, loss: 0.305552 \n",
      "Epochs:   35/ 100, loss: 0.404164 \n",
      "Epochs:   36/ 100, loss: 0.150520 \n",
      "Epochs:   37/ 100, loss: 0.118640 \n",
      "Epochs:   38/ 100, loss: 0.216181 \n",
      "Epochs:   39/ 100, loss: 0.214308 \n",
      "Epochs:   40/ 100, loss: 0.327342 \n",
      "Epochs:   41/ 100, loss: 0.294412 \n",
      "Epochs:   42/ 100, loss: 0.324542 \n",
      "Epochs:   43/ 100, loss: 0.484070 \n",
      "Epochs:   44/ 100, loss: 0.201783 \n",
      "Epochs:   45/ 100, loss: 0.282103 \n",
      "Epochs:   46/ 100, loss: 0.151516 \n",
      "Epochs:   47/ 100, loss: 0.102144 \n",
      "Epochs:   48/ 100, loss: 0.160755 \n",
      "Epochs:   49/ 100, loss: 0.245367 \n",
      "Epochs:   50/ 100, loss: 0.234907 \n",
      "Epochs:   51/ 100, loss: 0.138905 \n",
      "Epochs:   52/ 100, loss: 0.125513 \n",
      "Epochs:   53/ 100, loss: 0.121451 \n",
      "Epochs:   54/ 100, loss: 0.132818 \n",
      "Epochs:   55/ 100, loss: 0.352440 \n",
      "Epochs:   56/ 100, loss: 0.400756 \n",
      "Epochs:   57/ 100, loss: 0.557317 \n",
      "Epochs:   58/ 100, loss: 0.191180 \n",
      "Epochs:   59/ 100, loss: 0.221051 \n",
      "Epochs:   60/ 100, loss: 0.419294 \n",
      "Epochs:   61/ 100, loss: 0.227523 \n",
      "Epochs:   62/ 100, loss: 0.270497 \n",
      "Epochs:   63/ 100, loss: 0.324991 \n",
      "Epochs:   64/ 100, loss: 0.298088 \n",
      "Epochs:   65/ 100, loss: 0.395952 \n",
      "Epochs:   66/ 100, loss: 0.251809 \n",
      "Epochs:   67/ 100, loss: 0.299084 \n",
      "Epochs:   68/ 100, loss: 0.336015 \n",
      "Epochs:   69/ 100, loss: 0.220537 \n",
      "Epochs:   70/ 100, loss: 0.273173 \n",
      "Epochs:   71/ 100, loss: 0.141717 \n",
      "Epochs:   72/ 100, loss: 0.214908 \n",
      "Epochs:   73/ 100, loss: 0.243981 \n",
      "Epochs:   74/ 100, loss: 0.218204 \n",
      "Epochs:   75/ 100, loss: 0.285735 \n",
      "Epochs:   76/ 100, loss: 0.217050 \n",
      "Epochs:   77/ 100, loss: 0.156747 \n",
      "Epochs:   78/ 100, loss: 0.317904 \n",
      "Epochs:   79/ 100, loss: 0.228154 \n",
      "Epochs:   80/ 100, loss: 0.147586 \n",
      "Epochs:   81/ 100, loss: 0.180682 \n",
      "Epochs:   82/ 100, loss: 0.312574 \n",
      "Epochs:   83/ 100, loss: 0.269010 \n",
      "Epochs:   84/ 100, loss: 0.447109 \n",
      "Epochs:   85/ 100, loss: 0.338000 \n",
      "Epochs:   86/ 100, loss: 0.200234 \n",
      "Epochs:   87/ 100, loss: 0.403534 \n",
      "Epochs:   88/ 100, loss: 0.182438 \n",
      "Epochs:   89/ 100, loss: 0.205880 \n",
      "Epochs:   90/ 100, loss: 0.090158 \n",
      "Epochs:   91/ 100, loss: 0.404278 \n",
      "Epochs:   92/ 100, loss: 0.324778 \n",
      "Epochs:   93/ 100, loss: 0.248635 \n",
      "Epochs:   94/ 100, loss: 0.203188 \n",
      "Epochs:   95/ 100, loss: 0.140140 \n",
      "Epochs:   96/ 100, loss: 0.327924 \n",
      "Epochs:   97/ 100, loss: 0.356230 \n",
      "Epochs:   98/ 100, loss: 0.390000 \n",
      "Epochs:   99/ 100, loss: 0.179776 \n",
      "Epochs:  100/ 100, loss: 0.313679 \n",
      "Learning finished\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1 + epochs):\n",
    "    avg_loss = 0.0\n",
    "    total_batch = len(loader)\n",
    "\n",
    "    for X, y in loader:\n",
    "        # X.size = (100, 784)\n",
    "        # Y.size = (100, 784)\n",
    "        X = X.view(-1, 28 * 28).to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        forward = linear(X)\n",
    "        loss = criterion(forward, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_loss += loss / total_batch\n",
    "\n",
    "    print(f'Epochs: {epoch:4d}/{epochs:4d}, loss: {loss:.6f} ')\n",
    "\n",
    "print(f'Learning finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  tensor(0.8676, device='mps:0')\n",
      "Label:  0\n",
      "Prediction:  7\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    x_test = mnist_test.test_data.view(-1, 784).float().to(device)\n",
    "    y_test = mnist_test.test_labels.to(device)\n",
    "\n",
    "    pred = linear(x_test)\n",
    "    corr = torch.argmax(pred, 1) == y_test\n",
    "    acc = corr.float().mean()\n",
    "    print('Accuracy: ', acc)\n",
    "\n",
    "    r = random.randint(0, len(mnist_test) - 1)\n",
    "    X_single_data = mnist_test.test_data[r:r + 1].view(-1, 28 * 28).float().to(device)\n",
    "    Y_single_data = mnist_test.test_labels[r:r + 1].to(device)\n",
    "\n",
    "    print('Label: ', Y_single_data.item())\n",
    "    single_prediction = linear(X_single_data)\n",
    "    print('Prediction: ', torch.argmax(single_prediction, 1).item())\n",
    "\n",
    "    plt.imshow(mnist_test.test_data[r:r + 1].view(28, 28), cmap='Greys', interpolation='nearest')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('torchEnv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88d943a007d2125a0b14d68c169cdc93803a522f9f1f0256c556fb2c659dfa57"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
